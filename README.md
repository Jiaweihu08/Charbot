# Chitchatting Chatbo - A seq2seq model with attention.

### Motivation
	- Gain deepened understanding on NLP
	- Improve SW development understanding: development + deployment
	- Hands-on experience implementing seq2seq models with attention with TensorFlow
	- Familiarize model training and deployment on GCP

### Steps
	- Theoretical understanding on Encoder-Decoder based seq2seq conversational agent with attentions
	- Explore and preprocess Cornell movie-dialogs corpus dataset
	- Build encoder-decoder model with attention:
		1. Shared embedding layer for encoder and decoder
		2. Two GRU layer for both encoder and decoder
		3. Encoder with Luong's attention
	- Define training loop with teacher-forcing
	- Monitor training evolution with TensorBoard
	- Understand BLEU score, perplexity, and cross_entropy

----- In progress -----

	- Model training on AWS
	- Model deployment with Flask
